---
title: 'Machine Learning — api.ai + Android'
description: ''
pubDate: '2017-03-16T18:32:00.634Z'
heroImage: 'https://cdn-images-1.medium.com/max/800/1*zlRUcY7jmlrgx91DblgyuQ.png'
---

* * *

### Machine Learning — api.ai + Android

Embora ter o nosso agente no Facebook e a enviar imagens pode ser bastante útil para lojas e empresas/organizações, talvez você queria desenvolver um assistente pessoal: a sua própria [_Siri_](http://www.apple.com/ios/siri/) ou [_Cortana_](https://support.microsoft.com/en-us/help/17214/windows-10-what-is).

Lembrar que este é o 5º artigo da série Machine Learning. Se você não acompanhou esta série desde o ínicio, aí tem uma oportunidade:

[**Machine Learning — Entrando no mundo dos assistentes virtuais**  
_Aprenda a criar o seu próprio assistente virtual em 4 passos simples._medium.com](https://medium.com/@rosariopfernandes/ml-b7eba66e0e03 "https://medium.com/@rosariopfernandes/ml-b7eba66e0e03")[](https://medium.com/@rosariopfernandes/ml-b7eba66e0e03)

Como sempre, para começarmos uma aplicação Android, temos de criar o projecto no Android Studio. Não vou detalhar este passo assumindo que você já sabe fazer isso (caso não, [leia este artigo](https://nerdbegin.wordpress.com/2016/02/03/o-primeiro-projecto-com-android-studio/)).

### Adicionar o api.ai ao projecto Android

#### Adicionar as bibliotecas

Depois de criar o nosso projecto, temos que adicionar as bibliotecas do api.ai ao projecto Android. E fazemos isso adicionando dependencias ao gradle, basta colocar as seguintes linhas no ficheiro _build.gradle_ (app):

```groovy
compile 'ai.api:libai:1.3.5'
compile 'ai.api:sdk:2.0.2@aar'
compile 'com.android.support:appcompat-v7:23.2.1'
compile 'com.google.code.gson:gson:2.3'
compile 'commons-io:commons-io:2.4'
```

#### Adicionar permissões ao Manifest

No seu ficheiro **AndroidManifest.xml** que fica na pasta **app/src/main**, adicione as seguintes permissões (antes da tag _<application>_):

```xml
<uses-permission android:name="android.permission.INTERNET"/>
<uses-permission android:name="android.permission.RECORD_AUDIO" />
```

### Criar a Activity

#### Desenho da interface do utilizador (xml)

Vamos criar uma interface simples só para que você tenha uma noção de como funciona esta integração. A nossa Activity terá apenas uma TextView e um Button:

#### Conexão com o nosso agente

Vamos começar por permitir que a nossa aplicação receba as respostas do agente. Para isso, temos de ter uma classe que implementa a interface _AIListener_. Podemos implementar esta interface na nossa Activity:

```java
public class MainActivity extends AppCompatActivity implements AIListener {
```

Esta interface tem 6 métodos que você deve obrigatoriamente colocar na Activity:

```java
void onResult(AIResponse result){} // é aqui onde você processa o resultado da requisição (a resposta)
void onError(AIError error){} // chamado caso ocorra um erro
void onAudioLevel(float level){} // indica o nível do som quando o usuário está a falar
void onListeningStarted() // quando o microfone é activado
void onListeningCanceled(){} // quando o microfone é cancelado (porque o usuário cancelou ou ocorreu um erro)
void onListeningFinished(){} // quando o microfone é desactivado (porque o usuário terminou de falar)
```

Em seguida, vamos criar duas variáveis e inicializá-las:

```java
public class MainActivity extends AppCompatActivity implements AIListener{
    private AIConfiguration config;
    private AIService service;

    @Override
    protected void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        setContentView(R.layout.activity_main);

        config = new AIConfiguration("**CLIENT_ACCESS_TOKEN**",
                AIConfiguration.SupportedLanguages.Portuguese,//Altere esta linha de acordo com o idioma que voce escolheu na consola
                AIConfiguration.RecognitionEngine.System);
        service = AIService.getService(this, config);
        service.setListener(this);
    }
}
```

Substitua **CLIENT\_ACCESS\_TOKEN** pelo access token do seu agente. Para obter este token, basta ir às [definições do agente na consola do api.ai](https://console.api.ai/api-client/#/editAgent/).

![](https://cdn-images-1.medium.com/max/800/1*5ldVJL3mmI5R7BO2hrjz_Q.png)

#### Enviar requisições

Para a nossa aplicação poder enviar requisições por voz, basta adicionarmos um onClickListener ao nosso botão e chamar o metodo _startListening()_:

```java
button.setOnClickListener(new View.OnClickListener() {
    @Override
    public void onClick(View view) {
        service.startListening();
    }
});
```

#### Mostrar a resposta

E depois recebemos respostas e/ou erros da requisição nos métodos onResult e onError:

```java
@Override
public void onResult(AIResponse response) {
    Result result = response.getResult();

    // Obter os parametros caso existam
    String parameterString = "";
    if (result.getParameters() != null && !result.getParameters().isEmpty()) {
        for (final Map.Entry<String, JsonElement> entry : result.getParameters().entrySet()) {
            parameterString += "(" + entry.getKey() + ", " + entry.getValue() + ") ";
        }
    }

    // Show results in TextView.
    textView.setText("Query:" + result.getResolvedQuery() + //A frase que o utilizador usou
            "\nSpeech: " + result.getFulfillment().getSpeech() + //A resposta
            "\nParameters: " + parameterString); //Os parametros
}

@Override
public void onError(AIError error) {
    textView.setText(error.toString());
}
```

A Activity final fica assim:



E agora é so executar a aplicação no seu telemóvel ou emulador e você terá uma tela semelhante a esta:

![](https://cdn-images-1.medium.com/max/800/1*y5jbMUpB2q9zRNunKSuPRQ.png)

E pronto. Criar uma versão simplificada do [_Google Assistant_](https://assistant.google.com/) é tão simples quanto isto. Você pode obter o projecto inteiro no [GitHub](https://github.com/rosariopfernandes/meuassistentepessoal).

No [próximo artigo](https://medium.com/android-dev-moz/ml-actions-6cdf32bea767) veremos como permitir que a nossa aplicação realize acções de acordo com o Intent utilizado:

[**Machine Learning — Intents no api.ai (parte 2 — Acções e parametros)**  
_Ok, eu criei uma aplicação capaz de conversar comigo no Android. Mas eu tenho amigos para isso. Eu preciso de um…_medium.com](https://medium.com/android-dev-moz/ml-actions-6cdf32bea767 "https://medium.com/android-dev-moz/ml-actions-6cdf32bea767")[](https://medium.com/android-dev-moz/ml-actions-6cdf32bea767)
