<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Machine Learning — api.ai + Android</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Machine Learning — api.ai + Android</h1>
</header>
<section data-field="description" class="p-summary">
Embora ter o nosso agente no Facebook e a enviar imagens pode ser bastante útil para lojas e empresas/organizações, talvez você queria desenvolver um assistente pessoal: a sua própria Siri ou Cortana…
</section>
<section data-field="body" class="e-content">
<section name="0f54" class="section section--body section--first"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><figure name="f176" id="f176" class="graf graf--figure graf--leading"><img class="graf-image" data-image-id="1*zlRUcY7jmlrgx91DblgyuQ.png" data-width="1043" data-height="313" src="https://cdn-images-1.medium.com/max/800/1*zlRUcY7jmlrgx91DblgyuQ.png"></figure><h3 name="5895" id="5895" class="graf graf--h3 graf-after--figure graf--title">Machine Learning — api.ai + Android</h3><p name="c697" id="c697" class="graf graf--p graf-after--h3">Embora ter o nosso agente no Facebook e a enviar imagens pode ser bastante útil para lojas e empresas/organizações, talvez você queria desenvolver um assistente pessoal: a sua própria <a href="http://www.apple.com/ios/siri/" data-href="http://www.apple.com/ios/siri/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><em class="markup--em markup--p-em">Siri</em></a> ou <a href="https://support.microsoft.com/en-us/help/17214/windows-10-what-is" data-href="https://support.microsoft.com/en-us/help/17214/windows-10-what-is" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><em class="markup--em markup--p-em">Cortana</em></a>.</p><p name="e70c" id="e70c" class="graf graf--p graf-after--p">Lembrar que este é o 5º artigo da série Machine Learning. Se você não acompanhou esta série desde o ínicio, aí tem uma oportunidade:</p><div name="e1e6" id="e1e6" class="graf graf--mixtapeEmbed graf-after--p"><a href="https://medium.com/@rosariopfernandes/ml-b7eba66e0e03" data-href="https://medium.com/@rosariopfernandes/ml-b7eba66e0e03" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://medium.com/@rosariopfernandes/ml-b7eba66e0e03"><strong class="markup--strong markup--mixtapeEmbed-strong">Machine Learning — Entrando no mundo dos assistentes virtuais</strong><br><em class="markup--em markup--mixtapeEmbed-em">Aprenda a criar o seu próprio assistente virtual em 4 passos simples.</em>medium.com</a><a href="https://medium.com/@rosariopfernandes/ml-b7eba66e0e03" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="14c57826f0d1f9441e393135d9c9ecf7" data-thumbnail-img-id="1*LOyHOG13p2sMwEfCZVDKPw.png" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/1*LOyHOG13p2sMwEfCZVDKPw.png);"></a></div><p name="d413" id="d413" class="graf graf--p graf-after--mixtapeEmbed">Como sempre, para começarmos uma aplicação Android, temos de criar o projecto no Android Studio. Não vou detalhar este passo assumindo que você já sabe fazer isso (caso não, <a href="https://nerdbegin.wordpress.com/2016/02/03/o-primeiro-projecto-com-android-studio/" data-href="https://nerdbegin.wordpress.com/2016/02/03/o-primeiro-projecto-com-android-studio/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">leia este artigo</a>).</p><h3 name="b7b1" id="b7b1" class="graf graf--h3 graf-after--p">Adicionar o api.ai ao projecto Android</h3><h4 name="52ce" id="52ce" class="graf graf--h4 graf-after--h3">Adicionar as bibliotecas</h4><p name="adb4" id="adb4" class="graf graf--p graf-after--h4">Depois de criar o nosso projecto, temos que adicionar as bibliotecas do api.ai ao projecto Android. E fazemos isso adicionando dependencias ao gradle, basta colocar as seguintes linhas no ficheiro <em class="markup--em markup--p-em">build.gradle</em> (app):</p><pre name="6e03" id="6e03" class="graf graf--pre graf-after--p"><code class="markup--code markup--pre-code">compile &#39;ai.api:libai:1.3.5&#39;<br>compile &#39;ai.api:sdk:2.0.2@aar&#39;<br>compile &#39;com.android.support:appcompat-v7:23.2.1&#39;<br>compile &#39;com.google.code.gson:gson:2.3&#39;<br>compile &#39;commons-io:commons-io:2.4&#39;</code></pre><h4 name="450c" id="450c" class="graf graf--h4 graf-after--pre">Adicionar permissões ao Manifest</h4><p name="06a4" id="06a4" class="graf graf--p graf-after--h4">No seu ficheiro <strong class="markup--strong markup--p-strong">AndroidManifest.xml</strong> que fica na pasta <strong class="markup--strong markup--p-strong">app/src/main</strong>, adicione as seguintes permissões (antes da tag <em class="markup--em markup--p-em">&lt;application&gt;</em>):</p><pre name="50a8" id="50a8" class="graf graf--pre graf-after--p">&lt;<strong class="markup--strong markup--pre-strong">uses-permission</strong> android:<em class="markup--em markup--pre-em">name</em>=&quot;android.permission.INTERNET&quot;/&gt;<br>&lt;<strong class="markup--strong markup--pre-strong">uses-permission</strong> android:<em class="markup--em markup--pre-em">name</em>=&quot;android.permission.RECORD_AUDIO&quot; /&gt;</pre><h3 name="5fe0" id="5fe0" class="graf graf--h3 graf-after--pre">Criar a Activity</h3><h4 name="b2cc" id="b2cc" class="graf graf--h4 graf-after--h3">Desenho da interface do utilizador (xml)</h4><p name="4ccd" id="4ccd" class="graf graf--p graf-after--h4">Vamos criar uma interface simples só para que você tenha uma noção de como funciona esta integração. A nossa Activity terá apenas uma TextView e um Button:</p><figure name="5963" id="5963" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/rosariopfernandes/62f972f3bbea1829d54c434ed65ab68d.js"></script></figure><h4 name="108a" id="108a" class="graf graf--h4 graf-after--figure">Conexão com o nosso agente</h4><p name="a3ca" id="a3ca" class="graf graf--p graf-after--h4">Vamos começar por permitir que a nossa aplicação receba as respostas do agente. Para isso, temos de ter uma classe que implementa a interface <em class="markup--em markup--p-em">AIListener</em>. Podemos implementar esta interface na nossa Activity:</p><pre name="ffb4" id="ffb4" class="graf graf--pre graf-after--p"><code class="markup--code markup--pre-code">public class MainActivity extends AppCompatActivity implements AIListener {</code></pre><p name="5cb0" id="5cb0" class="graf graf--p graf-after--pre">Esta interface tem 6 métodos que você deve obrigatoriamente colocar na Activity:</p><pre name="d0e7" id="d0e7" class="graf graf--pre graf-after--p">void <strong class="markup--strong markup--pre-strong">onResult(</strong>AIResponse result<strong class="markup--strong markup--pre-strong">)</strong>{} // é aqui onde você processa o resultado da requisição (a resposta)<br>void <strong class="markup--strong markup--pre-strong">onError(</strong>AIError error<strong class="markup--strong markup--pre-strong">)</strong>{} // chamado caso ocorra um erro<br>void <strong class="markup--strong markup--pre-strong">onAudioLevel(</strong>float level<strong class="markup--strong markup--pre-strong">)</strong>{} // indica o nível do som quando o usuário está a falar<br>void <strong class="markup--strong markup--pre-strong">onListeningStarted()</strong> // quando o microfone é activado<br>void <strong class="markup--strong markup--pre-strong">onListeningCanceled()</strong>{} // quando o microfone é cancelado (porque o usuário cancelou ou ocorreu um erro)<br>void <strong class="markup--strong markup--pre-strong">onListeningFinished()</strong>{} // quando o microfone é desactivado (porque o usuário terminou de falar)</pre><p name="913a" id="913a" class="graf graf--p graf-after--pre">Em seguida, vamos criar duas variáveis e inicializá-las:</p><pre name="6e25" id="6e25" class="graf graf--pre graf-after--p">public class MainActivity extends AppCompatActivity implements AIListener{<br>    private AIConfiguration config;<br>    private AIService service;<br><br>    @Override<br>    protected void onCreate(Bundle savedInstanceState) {<br>        super.onCreate(savedInstanceState);<br>        setContentView(R.layout.<em class="markup--em markup--pre-em">activity_main</em>);<br><br>        config = new AIConfiguration(&quot;<strong class="markup--strong markup--pre-strong">CLIENT_ACCESS_TOKEN</strong>&quot;,<br>                AIConfiguration.SupportedLanguages.<em class="markup--em markup--pre-em">Portuguese</em>,//Altere esta linha de acordo com o idioma que voce escolheu na consola<br>                AIConfiguration.RecognitionEngine.System);<br>        service = AIService.getService(this, config);<br>        service.setListener(this);<br>    }<br><br>}</pre><p name="ea8a" id="ea8a" class="graf graf--p graf-after--pre">Substitua <strong class="markup--strong markup--p-strong">CLIENT_ACCESS_TOKEN </strong>pelo access token do seu agente. Para obter este token, basta ir às <a href="https://console.api.ai/api-client/#/editAgent/" data-href="https://console.api.ai/api-client/#/editAgent/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">definições do agente na consola do api.ai</a>.</p><figure name="3621" id="3621" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*5ldVJL3mmI5R7BO2hrjz_Q.png" data-width="609" data-height="175" src="https://cdn-images-1.medium.com/max/800/1*5ldVJL3mmI5R7BO2hrjz_Q.png"></figure><h4 name="4b48" id="4b48" class="graf graf--h4 graf-after--figure">Enviar requisições</h4><p name="71ec" id="71ec" class="graf graf--p graf-after--h4">Para a nossa aplicação poder enviar requisições por voz, basta adicionarmos um onClickListener ao nosso botão e chamar o metodo <em class="markup--em markup--p-em">startListening()</em>:</p><pre name="756c" id="756c" class="graf graf--pre graf-after--p">button.setOnClickListener(new View.OnClickListener() {<br>    @Override<br>    public void onClick(View view) {<br>        service.startListening();<br>    }<br>});</pre><h4 name="1d2f" id="1d2f" class="graf graf--h4 graf-after--pre">Mostrar a resposta</h4><p name="8b37" id="8b37" class="graf graf--p graf-after--h4">E depois recebemos respostas e/ou erros da requisição nos métodos onResult e onError:</p><pre name="e9a6" id="e9a6" class="graf graf--pre graf-after--p">@Override<br>public void onResult(AIResponse response) {<br>    Result result = response.getResult();<br><br>    // Obter os parametros caso existam<br>    String parameterString = &quot;&quot;;<br>    if (result.getParameters() != null &amp;&amp; !result.getParameters().isEmpty()) {<br>        for (final Map.Entry&lt;String, JsonElement&gt; entry : result.getParameters().entrySet()) {<br>            parameterString += &quot;(&quot; + entry.getKey() + &quot;, &quot; + entry.getValue() + &quot;) &quot;;<br>        }<br>    }<br><br>    // Show results in TextView.<br>    textView.setText(&quot;Query:&quot; + result.getResolvedQuery() + //A frase que o utilizador usou<br>            &quot;\nSpeech: &quot; + result.getFulfillment().getSpeech() + //A resposta<br>            &quot;\nParameters: &quot; + parameterString); //Os parametros<br>}<br><br>@Override<br>public void onError(AIError error) {<br>    textView.setText(error.toString());<br>}</pre><p name="ee4e" id="ee4e" class="graf graf--p graf-after--pre">A Activity final fica assim:</p><figure name="168e" id="168e" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/rosariopfernandes/3230f47938f917344d9dca30016920df.js"></script></figure><p name="18b8" id="18b8" class="graf graf--p graf-after--figure">E agora é so executar a aplicação no seu telemóvel ou emulador e você terá uma tela semelhante a esta:</p><figure name="9d5b" id="9d5b" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*y5jbMUpB2q9zRNunKSuPRQ.png" data-width="320" data-height="480" src="https://cdn-images-1.medium.com/max/800/1*y5jbMUpB2q9zRNunKSuPRQ.png"></figure><p name="0afc" id="0afc" class="graf graf--p graf-after--figure">E pronto. Criar uma versão simplificada do <a href="https://assistant.google.com/" data-href="https://assistant.google.com/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><em class="markup--em markup--p-em">Google Assistant</em></a> é tão simples quanto isto. Você pode obter o projecto inteiro no <a href="https://github.com/rosariopfernandes/meuassistentepessoal" data-href="https://github.com/rosariopfernandes/meuassistentepessoal" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">GitHub</a>.</p><p name="b939" id="b939" class="graf graf--p graf-after--p">No <a href="https://medium.com/android-dev-moz/ml-actions-6cdf32bea767" data-href="https://medium.com/android-dev-moz/ml-actions-6cdf32bea767" class="markup--anchor markup--p-anchor" target="_blank">próximo artigo</a> veremos como permitir que a nossa aplicação realize acções de acordo com o Intent utilizado:</p><div name="4ffd" id="4ffd" class="graf graf--mixtapeEmbed graf-after--p graf--trailing"><a href="https://medium.com/android-dev-moz/ml-actions-6cdf32bea767" data-href="https://medium.com/android-dev-moz/ml-actions-6cdf32bea767" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://medium.com/android-dev-moz/ml-actions-6cdf32bea767"><strong class="markup--strong markup--mixtapeEmbed-strong">Machine Learning — Intents no api.ai (parte 2 — Acções e parametros)</strong><br><em class="markup--em markup--mixtapeEmbed-em">Ok, eu criei uma aplicação capaz de conversar comigo no Android. Mas eu tenho amigos para isso. Eu preciso de um…</em>medium.com</a><a href="https://medium.com/android-dev-moz/ml-actions-6cdf32bea767" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="0b90880165dc21cf23b8126b13be3a49" data-thumbnail-img-id="1*P9fogFeO3KumEO2CzGH9ow.png" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/1*P9fogFeO3KumEO2CzGH9ow.png);"></a></div></div></div></section><section name="e9b0" class="section section--body section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><p name="b31e" id="b31e" class="graf graf--p graf--leading graf--trailing">Se você tem alguma dúvida ou sugestão, não hesite em me contactar pelo email <a href="mailto:rosariofernandes51@gmail.com" data-href="mailto:rosariofernandes51@gmail.com" class="markup--anchor markup--p-anchor" target="_blank">rosariofernandes51@gmail.com</a> ou pelo <a href="https://telegram.me/rosariopfernandes" data-href="https://telegram.me/rosariopfernandes" class="markup--anchor markup--p-anchor" rel="nofollow noopener noopener" target="_blank">Telegram</a>. Ficarei feliz por conversar com você. :)</p></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@thatfire.dev" class="p-author h-card">Rosário Pereira Fernandes</a> on <a href="https://medium.com/p/94d77658f6c6"><time class="dt-published" datetime="2017-03-16T18:32:00.634Z">March 16, 2017</time></a>.</p><p><a href="https://medium.com/@thatfire.dev/ml-android-94d77658f6c6" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on November 24, 2025.</p></footer></article></body></html>